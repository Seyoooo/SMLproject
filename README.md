# Project : Box-office score prediction

**Course:** Scalable Machine Learning and Deep Learning - Project

**Team Limoncello**: Iga Pawlak, Julien Horvat

## 1. Description

This project is a serverless ML pipeline that creates models for upcoming box office performance predictions of recently released films. The model is trained on well selected features of past films and solving a regression problem tries to infer on the revenue of new films. The datasource we chose is the [TMDB API](https://developer.themoviedb.org/reference/intro/getting-started), an online API giving a free access to a good amount of film description, frequently updated, and with performant and interesting query possibilities. One can get the access via an online formula. 

The pipeline uses Hopsworks for efficient storage (features and models), Huggingface web app for user interface, and Github Actions for workflows.

## 2. Structure and details

### 2.1. Struture of the project 

At the center of the system is Hopsworks. It receives and stores the features created in *movies_feature_pipeline.ipynb*, sends them to *movies_training_pipeline.ipynb* and get back a trained model, interacts with workflows and with Huggingface. The offline dataset is fetched from TMDB API in the feature pipeline. Data is also fetched in the workflows for daily inference, and from Huggingface for details of movies.

This project involves different online services. In the code, we need API private keys to access Hopsworks and TMDB API. We added them as secret keys on Github for the workflows, and you will not have access to them on the repository. If you want to run this code, you should either ask us the keys or create your owns. 

For clarity, all functions basic functions and functions for feature extraction and TMDB API interactions are coded in *utils.py*.

### 2.2 Features selection and pipeline

TMDB API gives acces to details about the movies (a primary key id, budget of the film, revenues, released date, runtime, title, overview, genre tc...) and interesting pre-computed features (vote_average of the movie on their website and popularity). One can access similar movies, crew and casting wit additional queries. Based on that, we computed feature we found relevant :
* *similar_revenues* an average of the revenues generated by movies associated by TMDB as related the movie target.
* *crew_popularity* the sum of key peoples popularity in the movie crew (director, producer, production manager etc...)
* *top_cast_popularity* the sum of top 10 casting's polularity.

We tried to identify the best features using feature selection algorithms (SelectKBest and RFE). However, we noticed that many interesting features were not available for recently released movies (popularity, vote average, vote count, etc...) as the film is new! Compiling this with the feature search results, we defined as promising features the set **['budget', 'crew_popularity', 'top_cast_popularity', 'similar_revenues']**. 

### 2.3 Training pipeline

Our best performance using a K-Neighbours Regressor.
![image](https://github.com/Seyoooo/SMLproject/assets/51091250/12d5ad84-92c0-4f7b-9d54-1d038e1ba323)

Comparison between the predicted and labeled values. 
![image](https://github.com/Seyoooo/SMLproject/assets/51091250/e51264fc-2cf1-43a2-b9f3-280b4ac65af6)


A basic neural network.
![image](https://github.com/Seyoooo/SMLproject/assets/51091250/4b4a1f2d-df33-4fa9-b470-c845d336d97e)


### 2.4 Workflows

There are two worksflows linked to Github actions :

* *movies_filling_database.py* was used to fill the offline feature group for training. Indeed scrapping the TMDB API takes time, and compute the features also. So we used Git GPU as nodes to scrap part of the database. The code and workflow is still on the repository but is not running anymore (only once a year..).

* *movies_inference_pipeline_daily.py* use the upcoming TMDB API to fetch the recent movies. It chooses a movie that is not yet in the feature group, predict his revenue and insert the new sample in the feature group. It runs on a daily basis.


### 2.5 HuggingFace app

### 2.6 Improvements

This prediction task was hard as the reasons of a success or a failure of a movie depends of many external parameters. For example, the success of the last Avatar is mainly due to the fact that everybody was waiting for the sequel, more than the value of the film itself. However, we have some ideas to enhance the performance of our system:
* Take into account external changes, like COVID pandemic.
* Data-centric : use more data, with verified features, and more balanced data on the revenues.
* Do a Time series split of training / test sets.
* Use a transformer to encode the Overview of the film add the encoding as a feature to a regression model.

## 3. How to run the code

First, you need to set up the API keys. Put your API Hopsworks key in a *hopsworks_api_key.txt* file, and the TMDB API key in a *headers.pkl* file (containing the dict with keys accept and Authorization). Put the two files in the root directory.

Then install the requirements using the *requirements.txt* file.

Then you can run seprately both notebooks to fill the training feature group and training a model. You can also run the python files on your local computer.

